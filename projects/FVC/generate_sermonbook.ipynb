{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2908dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle as pkl\n",
    "import re\n",
    "#from re import compile as recompile\n",
    "print('done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419d9bc-2140-4e84-9c45-4a3f118a826a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"code_dictionary.pkl\", \"rb\") as fp:\n",
    "    c2p_dict, bk2bkorder_dict, c2b_dict, c2ch_dict, c2v_dict, c2s_dict, c2t_dict, c2bvc_dict = pkl.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfd2e1-146e-4c58-9771-03d001697357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"x2code_dictionary.pkl\", \"rb\") as fp:\n",
    "    p2c_dict, b2c_dict = pkl.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78ca92-f1bb-4cce-81f7-3a6b6866ad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile regular expression rgx to cater math symbol '^'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61692271-45a2-4417-b9fc-6303b8fefd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgx = re.compile(r'([A-Za-z0-9=]+)\\^([A-Za-z0-9\\-]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569ac91-432e-46f5-9ab1-0bff5ebbd3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('checking of \"rgx.sub(r\\'$\\\\1^\\\\2$\\', \\'E=MC^2\\')\" :', rgx.sub(r'$\\1^\\2$', 'E=MC^-2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e469a86-5ee4-4f19-9006-22c35314835c",
   "metadata": {},
   "source": [
    "### print the latex document : sermon content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28920e4-79c2-479f-8a68-9d30ededa870",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../rep_common.txt', 'r') as fp:\n",
    "    rep_list = [ _.strip() for _ in fp.readlines() ]\n",
    "fp.close()\n",
    "rep_list = [ _.split(\", '\", 1) for _ in rep_list ]\n",
    "rep_list = [ [_[0], _[1][:-1]] for _ in rep_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5317a9c-b56d-400d-bf1a-d16fff2e31de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile regular expression rgx to cater math symbol '^'\n",
    "rgx = re.compile(r'([A-Za-z0-9=+\\-]+)\\^([A-Za-z0-9=+\\-]+)')\n",
    "print('checking of \"rgx.sub(r\\'$\\\\1^\\\\2$\\', \\'E=MC^-2\\')\" :', rgx.sub(r'$\\1^\\2$', 'E=MC^-2'))\n",
    "\n",
    "\n",
    "def cleanse_special_char(inputText):\n",
    "    txt2 = inputText\n",
    "    txt2 = txt2.replace('$','\\$') # preserve this here since its higher priority than in html arguments\n",
    "    txt2 = rgx.sub(r'$\\1^\\2$', txt2)\n",
    "    for rep_ in rep_list:\n",
    "        txt2 = txt2.replace(rep_[0], rep_[1])\n",
    "    txt2 = txt2.replace('&', ' and ') # preserve this here since its lower priority than in html arguments\n",
    "    txt2 = txt2.strip()\n",
    "    return txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d76b5-6b1d-4430-9236-b66a901676ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_list = list(p2c_dict.keys())\n",
    "print(sorted(p_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f45a03-c1b9-4314-885d-27e906b6f8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_in_year_range(code, year_range=[2012,2018]):\n",
    "    # tstr = c2t_dict.get(code, ' ')\n",
    "    # # print(tstr)\n",
    "    in_range = False\n",
    "    for yr in range(year_range[0], year_range[1] + 1):\n",
    "        # if str(yr) in tstr:\n",
    "        if str(yr) in code:\n",
    "            in_range = True\n",
    "            break\n",
    "    return in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e5c0b-aba3-4df5-a8f8-6ddb0c22ba5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./index_byt.csv\", \"r\") as fp:\n",
    "    lines = fp.readlines()\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf5425-ceb9-4846-a5b6-a1cadeb919e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('sermon count:', len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4963492-e78b-4a0b-952e-9a936130730d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgx_bv = re.compile(r'(?<=\\d)[_](?=\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb29d3-11e2-459d-b5bd-c56077185836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yfcx_sermon_title_processing(cc):\n",
    "    sstr = c2s_dict.get(cc, ' ')\n",
    "    sstr = re.sub(r'[0-9][0-9][0-9][0-9].[0-9][0-9].[0-9][0-9]', '', sstr) # remove date from title\n",
    "    sstr = rgx_bv.sub(':', sstr) # adjust bible verse , use ':' to replace '_'\n",
    "    sstr = sstr[:-13] # remove trailing youtube code\n",
    "    sstr = sstr.replace('網上直播', '')\n",
    "    sstr = cleanse_special_char(\n",
    "        sstr.replace('_','\\_').replace('&','\\&')\n",
    "    )\n",
    "    sstr = sstr.strip()\n",
    "    return sstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e911c-9d70-4383-9be8-e4b3b288faab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sermon tex generation\n",
    "progressStepCnt = 0\n",
    "# --------------------------------------\n",
    "# read the index table and only take\n",
    "# into account within desired year range\n",
    "# --------------------------------------\n",
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: reading in full index file\")\n",
    "with open('./index_byt.csv', 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "fp.close()\n",
    "\n",
    "sermon_tex_filepath = f\"../../build/FVC/sermon_FVC_2017-present.tex\"\n",
    "# --------------------------------------\n",
    "# print the latex document : prefix\n",
    "# --------------------------------------\n",
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: printing out prefixing\")\n",
    "_ = os.system(f\"cat ../prefix.tex | sed 's/粵語講道逐字稿/粵語講道逐字稿 2017-present/' | sed 's/Youtube Channel:/Youtube Channel: 宣道會錦繡堂 Fairview Church/' > \" + sermon_tex_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d5510-4eb5-4edb-a7f8-f435ac1348a2",
   "metadata": {},
   "source": [
    "## generate index table in chronic order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84b294-fba0-4723-a689-34140bf16fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: generate index in chronic order\")\n",
    "with open(\"./index_byt.csv\", \"r\") as fp:\n",
    "    lines = fp.readlines()\n",
    "fp.close()\n",
    "# --------------------------------------\n",
    "# index table sorted by chronic order\n",
    "# --------------------------------------\n",
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: writing TOC in chronic order\")\n",
    "with open(sermon_tex_filepath, \"a\") as fp:\n",
    "    sermonCnt = 0\n",
    "    fp.write(\"\\\\section{目錄\\\\small{(順時)}}\\n\")\n",
    "    fp.write(\"\\\\label{sec:index_chronic}\\n\")\n",
    "    fp.write(\"{ \\\\scriptsize\\n\")\n",
    "    # --------------------------------------\n",
    "    # start of TOC table\n",
    "    # --------------------------------------\n",
    "    fp.write(\"\\n\\n\\\\begin{xltabular}{\\\\textwidth}{|p{0.15\\\\textwidth} p{0.6\\\\textwidth}|p{0.07\\\\textwidth} p{0.1\\\\textwidth}|}\\n\") # lllr: bk+v/ch, theme, date, youtube-code\n",
    "    fp.write(\"\\\\hline\\n\")\n",
    "    # --------------------------------------\n",
    "    # lines is the line content in index_byt\n",
    "    # --------------------------------------\n",
    "    for lineId in range(len(lines)):\n",
    "        line = lines[lineId]\n",
    "        cc = line.split(\",\")[0]\n",
    "        # --------------------------------------\n",
    "        # only include this code cc if it is\n",
    "        # ready in the transcription folder\n",
    "        # --------------------------------------\n",
    "        if os.path.isfile(f'../../data/FVC/{cc}.txt'):\n",
    "            sermonCnt += 1\n",
    "            pstr = c2p_dict.get(cc, ' ')\n",
    "            bstr = c2b_dict.get(cc, ' ')\n",
    "            vstr = c2v_dict.get(cc, ' ')\n",
    "            sstr = c2s_dict.get(cc, ' ')\n",
    "            sstr = yfcx_sermon_title_processing(cc)\n",
    "            sstr = cleanse_special_char(\n",
    "                c2s_dict.get(cc, ' ').replace('_','\\_').replace('&','\\&')\n",
    "            )\n",
    "            tstr = c2t_dict.get(cc, ' ')\n",
    "            ystr = \"\\\\href{https://youtube.com/watch?v=\" + cc +\"}{\\\\texttt{ \" + cc.replace('_','\\_') + \"}}\"\n",
    "            fp.write(bstr + ' ' + vstr + \" & \" \\\n",
    "                     + \"\\\\hyperref[sec:\"+cc.replace('-','_')+\"]{\"+sstr+\"}\" + \" & \" \\\n",
    "                     + tstr + \" & \" \\\n",
    "                     + ystr \\\n",
    "                     + \" \\\\\\\\\\n\")\n",
    "    fp.write(\"\\\\end{xltabular}\\n\")\n",
    "    # --------------------------------------\n",
    "    # end of table sorted by chronic order\n",
    "    # --------------------------------------\n",
    "    fp.write(\"}\\n\")\n",
    "    print('sermon count in current book: %d' % sermonCnt)\n",
    "    fp.write(\"\\\\newpage\\n\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190404af-8524-4bb6-8af8-eb56c49b5c1c",
   "metadata": {},
   "source": [
    "## generate index in scriptual order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ffb26-ad37-46e7-9f0a-e4d2172f337f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: generate index in scriptual order\")\n",
    "with open(\"./index_byb.csv\", \"r\") as fp:\n",
    "    lines = fp.readlines()\n",
    "fp.close()\n",
    "# --------------------------------------\n",
    "# index table sorted by scriptual order\n",
    "# --------------------------------------\n",
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: writing TOC in scriptual order\")\n",
    "with open(sermon_tex_filepath, \"a\") as fp:\n",
    "    sermonCnt = 0\n",
    "    fp.write(\"\\\\section{目錄\\\\small{(順卷)}}\\n\")\n",
    "    fp.write(\"\\\\label{sec:index_scriptual}\\n\")\n",
    "    fp.write(\"{ \\\\scriptsize\\n\")\n",
    "    # --------------------------------------\n",
    "    # start of TOC table\n",
    "    # --------------------------------------\n",
    "    fp.write(\"\\n\\n\\\\begin{xltabular}{\\\\textwidth}{|p{0.15\\\\textwidth} p{0.6\\\\textwidth}|p{0.07\\\\textwidth} p{0.1\\\\textwidth}|}\\n\") # lllr: bk+v/ch, theme, date, youtube-code\n",
    "    fp.write(\"\\\\hline\\n\")\n",
    "    # --------------------------------------\n",
    "    # lines is the line content in index_byb\n",
    "    # --------------------------------------\n",
    "    for lineId in range(len(lines)):\n",
    "        line = lines[lineId]\n",
    "        cc = line.split(\",\")[0]\n",
    "        # --------------------------------------\n",
    "        # only include this code cc if it is\n",
    "        # ready in the transcription folder\n",
    "        # --------------------------------------\n",
    "        if os.path.isfile(f'../../data/FVC/{cc}.txt'):\n",
    "            sermonCnt += 1\n",
    "            pstr = c2p_dict.get(cc, ' ')\n",
    "            bstr = c2b_dict.get(cc, ' ')\n",
    "            vstr = c2v_dict.get(cc, ' ')\n",
    "            sstr = c2s_dict.get(cc, ' ')\n",
    "            sstr = yfcx_sermon_title_processing(cc)\n",
    "            sstr = cleanse_special_char(\n",
    "                c2s_dict.get(cc, ' ').replace('_','\\_').replace('&','\\&')\n",
    "            )\n",
    "            tstr = c2t_dict.get(cc, ' ')\n",
    "            ystr = \"\\\\href{https://youtube.com/watch?v=\" + cc +\"}{\\\\texttt{ \" + cc.replace('_','\\_') + \"}}\"\n",
    "            fp.write(bstr + ' ' + vstr + \" & \" \\\n",
    "                     + \"\\\\hyperref[sec:\"+cc.replace('-','_')+\"]{\"+sstr+\"}\" + \" & \" \\\n",
    "                     + tstr + \" & \" \\\n",
    "                     + ystr \\\n",
    "                     + \" \\\\\\\\\\n\")\n",
    "    fp.write(\"\\\\end{xltabular}\\n\")\n",
    "    # --------------------------------------\n",
    "    # end of table sorted by scriptual order\n",
    "    # --------------------------------------\n",
    "    fp.write(\"}\\n\")\n",
    "    print('sermon count in current book: %d' % sermonCnt)\n",
    "    fp.write(\"\\\\newpage\\n\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ccaaaa-e0b3-4830-8acc-91cb75237a5a",
   "metadata": {},
   "source": [
    "## generate main content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46114d-d97b-431b-a51f-c1af78d3bab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./index_byt.csv\", \"r\") as fp:\n",
    "    lines = fp.readlines()\n",
    "fp.close()\n",
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: generate main content\")\n",
    "cc_prev = ''\n",
    "cc_next = ''\n",
    "# --------------------------------------\n",
    "# lines is the line content in index_byt\n",
    "# --------------------------------------\n",
    "for lineId in range(len(lines)):\n",
    "    line = lines[lineId]\n",
    "    cc = line.split(\",\")[0]\n",
    "    cc_prev = lines[(lineId-1)%len(lines)].split(\",\")[0]\n",
    "    cc_next = lines[(lineId+1)%len(lines)].split(\",\")[0]\n",
    "    if os.path.isfile(f'../../data/FVC/{cc}.txt'):\n",
    "        with open(sermon_tex_filepath, \"a\") as fp:\n",
    "            #fp.write(\"\\n\\n\\\\section{\"+c2s_dict.get(cc).replace('_','\\\\_')+\"}\\n\")\n",
    "            sectionNameStr = ''\n",
    "            b = c2b_dict.get(cc)\n",
    "            sectionNameStr += b if b is not None else ''\n",
    "            v = c2v_dict.get(cc)\n",
    "            sectionNameStr += ' ' + v if b is not None and v is not None else ''\n",
    "            ch = c2ch_dict.get(cc)\n",
    "            sectionNameStr += ' ' + ch if b is not None and ch is not None and v is None else ''\n",
    "            fp.write(\"\\n\\n\\\\section{\"+sectionNameStr+\"}\\n\")\n",
    "            fp.write(\"\\\\label{sec:\"+cc.replace('-','_')+\"}\\n\")\n",
    "            sstr = yfcx_sermon_title_processing(cc)\n",
    "            sstr = cleanse_special_char(\n",
    "                c2s_dict.get(cc, ' ').replace('_','\\_').replace('&','\\&')\n",
    "            )\n",
    "            fp.write(\"\\\\textbf{\"+sstr+\"}\\n\")\n",
    "            fp.write(\"\\\\newline\\n\\\\newline\\n\")\n",
    "            fp.write(\"連結: \\\\href{https://youtube.com/watch?v=\" + cc +\"}{\\\\texttt{ https://youtube.com/watch?v=\" + cc.replace('_','\\_') + \"}} ~~~~ 語音日期: \" + c2t_dict.get(cc) + \" \\n\")\n",
    "            fp.write(\"\\\\newline\\n\\\\newline\\n\")\n",
    "            fp.write(\"\\\\hyperref[sec:\"+cc_prev.replace('-','_')+\"]{\\\\small{< < < PREV SERMON < < <}}\\n\")\n",
    "            fp.write(\"~\\n\")\n",
    "            fp.write(\"\\\\hyperref[sec:index_chronic]{\\\\small{[返順時目]}}\\n\")\n",
    "            fp.write(\"~\\n\")\n",
    "            fp.write(\"\\\\hyperref[sec:index_scriptual]{\\\\small{[返順卷目]}}\\n\")\n",
    "            fp.write(\"~\\n\")\n",
    "            fp.write(\"\\\\hyperref[sec:\"+cc_next.replace('-','_')+\"]{\\\\small{> > > NEXT SERMON > > >}}\\n\")\n",
    "            fp.write(\"\\\\newline\\n\\\\newline\\n\")\n",
    "        fp.close()\n",
    "        with open(sermon_tex_filepath, \"a\") as fp:\n",
    "            # ----------------------\n",
    "            # add the scripture part if not None\n",
    "            bvc_curr = c2bvc_dict.get(cc)\n",
    "            if bvc_curr is not None:\n",
    "                bvc_curr = bvc_curr.split(\"\\n\")\n",
    "                # first row shall be book + verse info\n",
    "                bvc_line = bvc_curr[0].strip() + \"\\n\"\n",
    "                fp.write(bvc_line)\n",
    "                fp.write(\"\\\\newline\\n\")\n",
    "                fp.write(\"\\\\begin{longtable}{cl}\\n\")\n",
    "                fp.write(\"\\\\hline\\n\\\\hline\\n\")\n",
    "                fp.write(\"章節 & 經文 (和合本修訂版)\\\\\\\\\\n\")\n",
    "                fp.write(\"\\\\hline\\n\")\n",
    "                for bvc_line in bvc_curr[1:]:\n",
    "                    bvc_line = bvc_line.strip()\n",
    "                    if len(bvc_line) > 0:\n",
    "                        if bvc_line != [ _.strip() for _ in bvc_curr if len(_.strip()) ][-1]:\n",
    "                            bvc_line += \" \\\\\\\\ \\\\\\\\ \\\\relax\\n\"\n",
    "                        else:\n",
    "                            bvc_line += \" \\\\\\\\ \\\\\\\\\\n\"\n",
    "                        si = bvc_line.find(\" \")\n",
    "                        if si == -1:\n",
    "                            bvc_line = \"& \" + \"\\\\begin{tabularx}{0.7\\\\textwidth}{X} \" + bvc_line + \" \\\\end{tabularx}\"\n",
    "                        else:\n",
    "                            bvc_line = bvc_line[:si].replace(\".\",\":\") +  \" & \" + \"\\\\begin{tabularx}{0.7\\\\textwidth}{X} \" + bvc_line[si+1:]\n",
    "                            nli = bvc_line.find(\" \\\\\\\\\") # newline char index\n",
    "                            bvc_line = bvc_line[:nli] + \" \\\\end{tabularx}\" + bvc_line[nli:]\n",
    "                        fp.write(bvc_line)\n",
    "                fp.write(\"[1ex]\\n\")\n",
    "                fp.write(\"\\\\hline\\n\\\\hline\\n\")\n",
    "                fp.write(\"\\\\end{longtable}\\n\")\n",
    "            # ----------------------\n",
    "            # add the sermon part\n",
    "            with open(\"../../data/FVC/\"+cc+\".txt\", \"r\") as fp_:\n",
    "                the_sermon_text = fp_.read()\n",
    "            fp_.close()\n",
    "            the_sermon_text = cleanse_special_char(the_sermon_text)\n",
    "            the_sermon_text = the_sermon_text.replace(\"\\\\n\\\\n\",\"\\\\n\")\n",
    "            textlines = the_sermon_text.split(\"\\n\")\n",
    "            _textrow_cnt = 0\n",
    "            textline_prev = ''\n",
    "            for textline in textlines:\n",
    "                if textline == textline_prev:\n",
    "                    textline_prev = textline\n",
    "                    continue\n",
    "                else:\n",
    "                    textline_prev = textline\n",
    "                _textrow_cnt += 1\n",
    "                if _textrow_cnt % 40 == 1:\n",
    "                    fp.write(\"$^{%d}$\" % _textrow_cnt)\n",
    "                if textline.count('$') == 1:\n",
    "                    # if the text line contains odd number of\n",
    "                    # dollar sign '$', it would probably bring up error\n",
    "                    # over 95% of the situation is that there only has 1 '$' sign\n",
    "                    textline = textline.replace('$', '\\\\$')\n",
    "                fp.write(textline + \"\\n\")\n",
    "                if _textrow_cnt % 40 == 0:\n",
    "                    fp.write(\"\\n\")\n",
    "            fp.write(\"\\\\newpage\\n\\n\")\n",
    "        fp.close()\n",
    "\n",
    "progressStepCnt += 1\n",
    "print(f\"Step {progressStepCnt}: generate afterward and postfix\")\n",
    "# --------------------------------------\n",
    "# print the latex document : afterword\n",
    "# --------------------------------------\n",
    "_ = os.system(\"cat ../afterword.tex >> \" + sermon_tex_filepath)\n",
    "# --------------------------------------\n",
    "# print the latex document : postfix\n",
    "# --------------------------------------\n",
    "_ = os.system(\"cat ../postfix.tex >> \" + sermon_tex_filepath)\n",
    "print(\"done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58257a32-cbbd-4fc2-82cf-59b4d885e537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedb818-1df2-4beb-b43d-aca49e01b603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

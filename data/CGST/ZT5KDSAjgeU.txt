(音樂)。
大家好,多謝Felix和院長帶我們分別從哲學和神學的角度。
去認識探討AI的本質、發展。
以至上帝、人和科技之間的關係。
如果他們的說法是宏觀地說到人類的生存、生命的問題。
來到這部分,我想把鏡頭拉近一點。
或者我們在這一刻最關心、最擔心的。
都是開始時說的生計、生活的問題。
開始時,Felix帶我們看了一些高危的行業。
如果很概括地想,那些工作如果是重複性高。
那些專業是處理資料、處理一些規則的時候。
或者是一些前線的工作很容易被自動化。
可能那些是相對高危的工作。
不過過去這大半年,如果是一年前。
我們會覺得創意工業是很安全的。
科技怎能做到人類的創意呢?。
不過大家看到,過去大半年。
文字、圖像、影像的工作是首當其衝。
反過來,我們不要聽完到現在。
大家不知道有沒有覺得「嗯,怎樣啊?」。
我們正面一點反過來,問一下AI。
其實有什麼工作沒那麼容易被人工智能所取代呢?。
我就問Google,不要經常問GPT。
它就給了我這十個。
這十個,不知道大家有沒有成為其中一份子。
如果我們又很概括地看。
這些職業對人的身心靈的需要。
它會作出一些支援、治療、發展。
滿足人類對那些美、對愛心、對關係的追求。
這一類的職業,或者暫時來說都是安全的。
除了工作被取代之外。
殺到埋身的AI的倫理問題又何止那麼少。
你每一天聽新聞,其實都有很多關於AI的討論。
剛才提到的自動化的決策系統。
是不是真的那麼成熟安全呢?。
自動駕駛已經搞了很久了。
還不至於很安全地去搭這些車。
演算法背後是不是有黑箱作業。
或者是用什麼數據來做。
這些數據會不會有偏見呢?。
大家最擔心或者最附身的是假新聞、假資訊。
其實越來越難分辨。
最近大半年大家應該每天都收到兩至三個不知從何而來的電話。
假新聞的技術越來越成熟。
令到不單止人類可以讓它成為工具。
更加成為騙徒的工具。
版權問題、私隱問題、監控問題。
剛才提到的這些問題好像比答案更加多。
劇情其實很熟悉。
我們回顧過去幾十年的科技短短的發展歷史。
其實我們看到一個模式。
每逢一個新的浪潮的科技出現的時候。
首先會帶來一陣的亢奮和憂慮。
過度的亢奮和過度的憂慮。
其實是源自於相信科技能夠決定一切。
決定人類的未來。
一種科技決定論。
無論你帶著這個決定論。
是覺得很樂觀地認為科技能夠解決人類生活的問題。
或者很悲觀地覺得。
沒有了,AI始終都會取代人類。
兩者其實都會認為科技的發展彷彿神一般的存在。
在主宰人類的未來。
不過我們站在最前線經歷了這幾十年的科技的人。
去回顧這些歷史的時候。
我們發現科技發展不是一條線。
不是一種決定性的力量。
每逢有新的事情發展的時候。
過度的亢奮和過度的憂慮之後。
社會會進入一種初商的階段。
各種的聲音就會被引入討論。
今晚都是其中一個例子。
AI的可能性、發展的政策、人類的權益、潛在的危機。
各種即時的害處和悲憶。
有沒有濫用技術的防止方法等等。
對自然生態的影響等等。
很多人都會加入這個討論。
初商和國力的過程裡面。
社會其實未必一定會達到一定的共識。
或者只有一個單一的答案。
不過在討論初商國力的過程裡面。
我們會塑造人類和科技如何來共存。
正如剛才Felix所說的共生的關係。
社會學家就會覺得是一種科技的社會形素。
一個社會形式的建構過程。
如果我們從這個角度去看的話。
我們就要問教會、信仰群體。
從什麼角度來參與建構初商的過程。
我們能不能夠化被動為主動。
讓我們對AI的憂慮轉化成為一種塑造的力量。
參與建設AI成為一個有道德的產物。
或者在發展的過程和成品上有倫理的基礎。
讓AI再次置放在剛才院長所說的。
上帝創造心意裡面一個合適的位置。
說到AI有道德。
其實信任的AI、道德的AI、責任的AI。
這些名稱並不是新鮮的事物。
歐盟早幾年已經列出了一系列的原則。
說什麼是可信的AI。
或者我們今天也可以從這個角度出發。
看看信仰群體能夠帶來什麼樣的思考。
其實香港政府也有類似的人工智能道德框架。
不過是大同小異。
這裡列出的七項原則。
其實每一項都可以用來做一個單獨的探討和反思。
不過今天時間所限。
我特別想說第一項和第七項。
對於無論你今天是在做AI或者在用AI。
可以作為一個思考的起點。
人類自主和監督。
這個原則大概是說AI要尊重人的自主權和決策。
讓每個人能夠對AI的系統具有最終的控制權。
並且要提供一個透明和可以理解的輸出。
無論AI的能力發展到何等強大的地步。
其實人類的確要堅持一個道德主體。
這個不可以替代的角色。
其實近來對AI發展的討論。
大部分的討論都認為人類自主和監督是很重要的。
Human in the loop這種AI和人類一起工作的發展和應用。
基本上是一個共識。
不過我們要再問下去。
這個所謂人類自主的Human agency是一個怎樣的自主呢?。
這裡所說的人類是否所有人類都有權自主呢?。
還是只是某一部分的人呢?。
是否所有用戶都有最大程度的自主。
還是只是科技企業的管理層呢?。
剛才Elon Musk他們簽了一個宣言。
後來Elon Musk自己就決定發展自己的AI。
因為他覺得自己的AI才可以阻止人類的滅亡。
他們是一個這樣的想法。
還是政府監管的人呢?。
還是最後都落在程式人手上呢?。
事實上這些人所擁抱的價值觀。
是會決定他們發展AI的項目的潛藏邏輯。
AI怎樣去學習。
用什麼數據去學習。
學習什麼東西。
限制什麼東西。
輸出什麼東西。
其實都是以這部分人的價值觀去塑造。
其實你用開ChartGP你就知道。
有些東西是不會回答你的。
但誰決定這些東西是不會回答的呢?。
所以有很多權力的爭論其實在其中。
對於我們今天來說。
與其去問AI的權力應該歸屬什麼人。
什麼角色。
倒不如我們去問。
要自主和監督AI的人類。
其實應該擁有什麼生命的質素。
擁有什麼品格和能力呢?。
如果將我們的焦點放在品格質素。
而不是角色的權力。
那麼基督教會就有很多東西可以說了。
畢竟很多基督徒每天散落在不同職場的崗位上。
為主、為人類、為世界去盡忠、去工作。
當中不缺乏很多的企業家、公務員。
甚至是程式人。
甚至是一般的使用者。
剛才院長提到發展科技要操練敬虔和美德。
比起發展技術更加重要。
面對AI人要去自主自由。
想去駕馭科技而不是被科技操控。
我就引用後世的一句說話。
如果看自由不是一種狀態、一個status。
而是一種技巧。
從這個角度來看有德性的人才能得到自由。
如果將人類的自由看成一種技巧、一種能力。
而不是一種狀態。
我們很自然地將關注點不是爭取status。
而是我們怎樣訓練自己成為有技巧、一種有德性的發展。
這種技巧不是一種技術技巧。
不是叫大家上AI課或讀程式學位。
而是一種德性的發展。
我用教育界作為一個例子。
當ChartGBT出現時教育界很擔心。
以往的教學和評核方法在AI新世界不再可行。
於是有學校馬上禁止使用。
亦有人會去發展AI偵測的技術。
嘗試用技術、規管的層面去對應這些問題。
不過各種技術走到今天。
很多實測都告訴我們其實不是太理想。
人如果有心走漏洞、有心走捷徑。
現在實在太多方法、太方便。
去到最後似乎發展人類的品格教育。
培育對AI有自主、自由的品格的能力才是出路。
正如侯氏所說,有德性的人才能得到自由。
當然今天說到的只是一個起始點。
面對這個新世界,這些品格是甚麼來的。
如何去培養呢?。
我相信這個所謂的起點大家要繼續探討和反省。
第二個想提的原則是負責任的問題。
這裡提到在AI的開發、部署和使用中所涉及的人。
應該對AI系統的結果和影響要去負責任。
確保一個透明負責任和擁有一個補救的機制。
這個原則。
對於我們來說,第二點這個負責任的AI。
可以說是第一點的延伸或例子。
因為有德性的人自然會為自己的行為的決定去負責任。
我們活在一個世代裏面。
讓我們覺得有時這些文化很容易令人害怕去作決定、選擇。
因為作選擇要面對結果。
面對結果的時候就要為這些結果負責任。
AI就提供了一個逃避責任的出口和藉口。
早前有一個科技公司經濟不要裁員。
對外公佈裁了一百多人。
他的說法是說我全部是根據AI的判斷去作出。
誰可以留下,誰要走。
感覺像什麼呢?比拉多,比拉多洗手。
不關我的事,這班人要殺耶穌。
我只是執行這班人的決定。
這個說法當然被人大力批評。
AI的決定去解僱這班人是根據什麼原則、數據。
有沒有人在參與其中。
AI成為了解釋一切關鍵字。
當中的運作沒有人知曉。
後來有內部的電郵流了出來。
原來AI是根據員工的數碼足跡。
數碼足跡來判斷一班人的低生產力。
數碼足跡大概是指你去過什麼網站。
用過什麼APP。
去過多久,做過什麼。
然後AI就用什麼演算法去推斷員工的低生產力。
如果是這樣,無論是被解僱或是留下的人。
對於他們有多大的說服力。
對於留下後在公司工作的同事。
他們會怎樣繼續工作下去。
其實是會產生很大的影響。
AI參與人類的決定其實不一定是壞事。
透過它可能幫到我們去多一些資料、一些角度。
但是AI的資料、角度不可以成為人逃避責任的藉口。
人也有責任去解釋AI是怎樣運作得出這些結果。
當然這些暫時只是一些少數。
未成為一個主流。
不過也足以叫我們去問。
人的責任究竟是否真的可以外判給AI。
對於我們基督徒來說,責任不單止是這樣。
責任更加是要面對上帝、面對被造的世界。
尤其是弱小的群體。
在AI新世界的處境裡。
弱小不單止是孤寡老弱。
也包括了在數碼世代裡被邊緣化。
欠缺一些科技的能力。
而去面對失業甚至是生活困難的人。
我們開發或使用AI的人。
必須去問這個AI的應用。
對哪些人帶來了負面的影響。
怎樣去舒緩、怎樣去幫助、怎樣去補救。
怎樣去保護、預防這些負面的影響。
我們不單止要看它正面的可能性。
要去負責任地讓AI成為弱小的幫助。
而不是一些新的障礙。
最後我想用一個正面的例子。
今天大家聽了很多令人驚嚇的故事。
另一個教育界的例子。
其實AI可以做到什麼呢?。
Khan Academy是美國一個非牟利的機構。
設立網上教育資源的平台。
它的使命是要向世界任何地方。
任何的小朋友都提供一些免費的教育。
教育界的朋友都聽過。
最新他們有一個項目叫AI Chatbot。
目標是讓這個Chatbot成為小朋友的個人導師。
畢竟不是世界各地的人都有免費教育。
或者是有老師去教他們。
一般的網上教育資源也未必可以針對小朋友個別學習的問題。
這個Chatbot就好像ChatGPT一樣。
你可以問他學習上的問題。
不過和ChatGPT不同。
他不會直接給你答案。
大家可以看到他的一些對答。
就像老師一樣,一步一步去引導小朋友思考答案。
大部分我們都只是認識某些大品牌的AI Chatbot。
人可以打一些提示去操作,操控他得到任何的答案。
這個AI Chatbot的設計者。
首先去問一個問題。
教育的目的是什麼。
然後按照目的,按照他專業的認識去設計。
去限制,去引導,去將AI塑造成為一個按教育目的而成的輔助工具。
教會,包括各行各業的基督徒。
無論你是AI的開發者或者是使用者。
面對這個新的世界。
我們是否可以化被動為主動。
讓我們將對AI的憂慮轉化為一些塑造的力量。
因為說到首先要成為一個有德性的自由人。
有能力去反思。
勇於去負責。
勇於去改正。
為他者,為弱勢而活。
讓AI成為有品格的輔助工具。
將AI置放在上帝創造心意的適當位置。
或者今天的教會,信仰的群體要繼續思考和行動的課題。
(音樂)。

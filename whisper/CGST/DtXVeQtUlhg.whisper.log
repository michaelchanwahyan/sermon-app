
[00:00:00.000 --> 00:00:07.600]  (音樂)
[00:00:07.600 --> 00:00:10.600]  大家好,吃飯了
[00:00:10.600 --> 00:00:15.200]  歡迎大家來到AI新世界的講座
[00:00:15.200 --> 00:00:17.200]  這是我代表忠臣
[00:00:17.200 --> 00:00:21.000]  亦代表忠臣的信仰及公共價值研究中心
[00:00:21.000 --> 00:00:22.600]  歡迎大家來到
[00:00:22.600 --> 00:00:26.000]  這個題目「AI新世界」
[00:00:26.000 --> 00:00:28.600]  有些人可能都會想到
[00:00:28.600 --> 00:00:33.000]  其實是跟一本小說「美麗新世界」有關
[00:00:33.000 --> 00:00:35.800]  當然那本小說的題目
[00:00:35.800 --> 00:00:38.600]  Odrys Huxley
[00:00:38.600 --> 00:00:41.800]  在1932年的小說
[00:00:41.800 --> 00:00:44.200]  那時候已經開始在問
[00:00:44.200 --> 00:00:46.400]  未來的世界會怎樣呢?
[00:00:46.400 --> 00:00:48.400]  人會更加開心
[00:00:48.400 --> 00:00:52.200]  還是會活在一個被壓迫的環境之下呢?
[00:00:52.200 --> 00:00:55.200]  可能大家來到都開始會問這個問題
[00:00:55.200 --> 00:00:58.000]  AI又會帶給我們甚麼影響呢?
[00:00:58.000 --> 00:01:02.200]  有幾個字大家後面的人未必看到
[00:01:02.200 --> 00:01:04.200]  要頭兩行的人才看到
[00:01:04.200 --> 00:01:07.000]  左下角有一個很小的字
[00:01:07.000 --> 00:01:10.800]  寫著Source AI繪圖
[00:01:10.800 --> 00:01:13.800]  即是這個公仔是AI畫出來的
[00:01:13.800 --> 00:01:16.000]  不知道有沒有給你一種感覺
[00:01:16.000 --> 00:01:18.800]  如果你是做Graphic Design的
[00:01:18.800 --> 00:01:21.800]  是不是你的工作都受到威脅呢?
[00:01:21.800 --> 00:01:27.600]  所以我們今天請了三位重量級的講員
[00:01:27.600 --> 00:01:30.200]  來跟我們分享
[00:01:30.200 --> 00:01:33.200]  三位講員分別第一位是
[00:01:33.200 --> 00:01:36.200]  盧敦恒Felix先生
[00:01:36.200 --> 00:01:39.600]  他是加拿大西門飛沙
[00:01:39.600 --> 00:01:43.800]  Simon Fraser的大學博士生
[00:01:43.800 --> 00:01:47.200]  他研究的題目就是關於
[00:01:47.200 --> 00:01:49.400]  Technology或者Philosophy
[00:01:49.400 --> 00:01:53.400]  跟AI有關的一些博士論文
[00:01:53.400 --> 00:01:57.800]  他跟一位所謂Philosophy of Technology
[00:01:57.800 --> 00:01:59.800]  科技哲學的大師
[00:01:59.800 --> 00:02:04.600]  Andrew Finberg寫論文的
[00:02:04.600 --> 00:02:06.800]  如果你想知道甚麼是科技哲學
[00:02:06.800 --> 00:02:09.600]  聽完Felix就知道了
[00:02:09.600 --> 00:02:11.000]  希望你知道了
[00:02:11.000 --> 00:02:14.200]  他的職業也是一個programmer
[00:02:14.200 --> 00:02:16.400]  做了多年的programmer
[00:02:16.400 --> 00:02:19.000]  第二位就是我們的院長
[00:02:19.000 --> 00:02:20.400]  黃國維院長
[00:02:20.400 --> 00:02:23.000]  甘信禹教席顧教授 陳克火
[00:02:23.000 --> 00:02:28.800]  他也是科技的神學反省
[00:02:28.800 --> 00:02:32.400]  也是他的專長之一
[00:02:32.400 --> 00:02:35.800]  Felix就比較從一個大一點的圖畫
[00:02:35.800 --> 00:02:41.400]  AI對整個社會的影響這方面去問
[00:02:41.400 --> 00:02:46.000]  跟著Bernard院長就會有一些神學的反省
[00:02:46.000 --> 00:02:50.200]  最後一位的講員就是楊家強先生
[00:02:50.200 --> 00:02:55.600]  楊家強先生是數碼科技公司的創辦人
[00:02:55.600 --> 00:03:00.400]  也是Durham道倫大學的文學碩士
[00:03:00.400 --> 00:03:04.600]  研究數碼神學的問題
[00:03:04.600 --> 00:03:09.200]  Felix也是我們忠臣
[00:03:09.200 --> 00:03:16.400]  幫我們推動數碼學習的一位同工
[00:03:16.400 --> 00:03:19.400]  所以其實我經常都仰望他
[00:03:19.400 --> 00:03:21.400]  因為我也不知道什麼叫數碼學習
[00:03:21.400 --> 00:03:23.400]  不懂就仰望他
[00:03:23.400 --> 00:03:26.800]  Felix 對不起 Alex
[00:03:26.800 --> 00:03:30.000]  主要從職場的角度
[00:03:30.000 --> 00:03:34.000]  AI會帶給我們職場有什麼挑戰呢
[00:03:34.000 --> 00:03:39.200]  三個不同的角度來討論AI這個問題
[00:03:39.200 --> 00:03:43.000]  接著就略為介紹一下今天的程序
[00:03:43.000 --> 00:03:45.000]  三位講員會先後上來
[00:03:45.000 --> 00:03:48.400]  接著我們會有一個互動交流的時間
[00:03:48.400 --> 00:03:51.000]  我會請三位講員上台
[00:03:51.000 --> 00:03:53.400]  接著我會跟三位講員
[00:03:53.400 --> 00:03:56.400]  首先有一個互相問問題
[00:03:56.400 --> 00:03:58.400]  聊聊天的時間
[00:03:58.400 --> 00:04:00.400]  接著到8點50分
[00:04:00.400 --> 00:04:04.400]  就會開始給大家問問題的時間
[00:04:04.400 --> 00:04:08.000]  由8點50分到9點半左右
[00:04:08.000 --> 00:04:10.400]  就是大家問問題的時間
[00:04:10.400 --> 00:04:16.400]  到時會有一個咪放在通道中間
[00:04:16.400 --> 00:04:20.400]  同時也有一個WhatsApp號碼
[00:04:20.400 --> 00:04:24.800]  到通道出來的時候你會看到WhatsApp號碼
[00:04:24.800 --> 00:04:26.800]  同工很好
[00:04:26.800 --> 00:04:31.600]  講完通道後每頁的右上角都有WhatsApp號碼
[00:04:31.600 --> 00:04:33.600]  所以你聽到不知道哪個環節
[00:04:33.600 --> 00:04:35.600]  你忽然間想問一個問題
[00:04:35.600 --> 00:04:38.800]  你就可以WhatsApp
[00:04:38.800 --> 00:04:40.800]  把你的問題寫下
[00:04:40.800 --> 00:04:42.800]  到問答的時間
[00:04:42.800 --> 00:04:45.800]  當然我們看看有多少人問問題
[00:04:45.800 --> 00:04:48.800]  就會盡量把大家的問題提出來
[00:04:48.800 --> 00:04:53.800]  看看講員會給我們甚麼答案
[00:04:53.800 --> 00:04:56.800]  其實我沒有介紹自己
[00:04:56.800 --> 00:04:58.800]  不過不需要介紹雷敬業
[00:04:58.800 --> 00:05:03.800]  所以接著我會把時間交給三位講員
[00:05:03.800 --> 00:05:05.800]  三位講員會輪流上台
[00:05:05.800 --> 00:05:07.800]  首先請Felix上台
[00:05:08.800 --> 00:05:15.800]  (掌聲)
[00:05:15.800 --> 00:05:18.800]  很感謝鍾神今晚的邀請
[00:05:18.800 --> 00:05:24.800]  讓我有機會在此和大家一起參與討論AI的神學研討會
[00:05:24.800 --> 00:05:28.800]  今晚我會由宏觀和哲學的角度
[00:05:28.800 --> 00:05:32.800]  去看AI將會對社會帶來甚麼威脅
[00:05:32.800 --> 00:05:36.800]  我會先解釋幾個AI如何影響社會的批判
[00:05:36.800 --> 00:05:39.800]  然後再用不同的哲學觀點去分析
[00:05:39.800 --> 00:05:41.800]  面對著AI帶來的威脅
[00:05:41.800 --> 00:05:44.800]  究竟我們人類可以有甚麼出路呢
[00:05:44.800 --> 00:05:49.800]  AI Artificial Intelligence這個名字
[00:05:49.800 --> 00:05:51.800]  其實是在1956年
[00:05:51.800 --> 00:05:55.800]  一班初期研究人工智能的電腦科學家
[00:05:55.800 --> 00:05:57.800]  第一次作業的時候改的
[00:05:57.800 --> 00:06:00.800]  而在初期,即是頭十多年
[00:06:00.800 --> 00:06:02.800]  AI的確有很多很重要的發展
[00:06:02.800 --> 00:06:05.800]  而這些發展也引起當時社會的關注
[00:06:05.800 --> 00:06:08.800]  所以在50-60年代就有很多科幻小說
[00:06:08.800 --> 00:06:11.800]  例如2001 Space Odyssey或Blade Runner
[00:06:11.800 --> 00:06:15.800]  都喜歡用一些與人工智能有關的主題
[00:06:15.800 --> 00:06:17.800]  作為故事的題材
[00:06:17.800 --> 00:06:19.800]  不過到了80-90年代
[00:06:19.800 --> 00:06:21.800]  一個現在被稱為AI Winter
[00:06:21.800 --> 00:06:23.800]  即是人工智能寒冬的年代
[00:06:23.800 --> 00:06:26.800]  人工智能的研發就停滯不前
[00:06:26.800 --> 00:06:28.800]  沒有甚麼明顯的突破
[00:06:28.800 --> 00:06:31.800]  所以在我讀電腦的時候就沒有人講AI
[00:06:31.800 --> 00:06:35.800]  但很多人都覺得人工智能只是不切實際的夢想
[00:06:35.800 --> 00:06:38.800]  到了十多年前左右
[00:06:38.800 --> 00:06:42.800]  AI才再一次有重大和突破性的發展
[00:06:42.800 --> 00:06:45.800]  簡單來說,因為社交媒體已經成為主流
[00:06:45.800 --> 00:06:49.800]  所以科技公司儲存了大量的數據
[00:06:49.800 --> 00:06:52.800]  而這些數據就可以用來訓練一些
[00:06:52.800 --> 00:06:55.800]  所謂的複雜的深入學習模式
[00:06:55.800 --> 00:06:58.800]  深入學習就是一些方法可以在龐大的數據當中
[00:06:58.800 --> 00:07:00.800]  找到一些重要的數據模式
[00:07:00.800 --> 00:07:04.800]  而這些科技公司就利用這些數據模式
[00:07:04.800 --> 00:07:06.800]  去開發新的產品
[00:07:06.800 --> 00:07:10.800]  所以很多以前軟件工程師做不到的產品
[00:07:10.800 --> 00:07:12.800]  現在都做到了
[00:07:12.800 --> 00:07:14.800]  例如有網上監控
[00:07:14.800 --> 00:07:16.800]  無人駕駛車
[00:07:16.800 --> 00:07:18.800]  人臉識別系統
[00:07:18.800 --> 00:07:20.800]  醫療手術診斷
[00:07:20.800 --> 00:07:22.800]  又或者最近出的檢查GPT
[00:07:22.800 --> 00:07:26.800]  這些產品背後都是用了深入學習的方法做出來的
[00:07:29.800 --> 00:07:33.800]  所以,AI的確可以帶給人類很多方便和好處
[00:07:33.800 --> 00:07:37.800]  但是AI也可以帶給社會負面的影響
[00:07:37.800 --> 00:07:40.800]  而近來,越來越多社會學家和哲學家
[00:07:40.800 --> 00:07:43.800]  都為這些負面的影響而擔憂
[00:07:43.800 --> 00:07:47.800]  第一個擔憂就是全世界各行各業
[00:07:47.800 --> 00:07:51.800]  都可能會面臨被AI取代的威脅
[00:07:51.800 --> 00:07:53.800]  有社會學家認為
[00:07:53.800 --> 00:07:56.800]  在將來的社會很有可能會有一大班人
[00:07:56.800 --> 00:07:59.800]  都需要面對長期失業的狀況
[00:07:59.800 --> 00:08:01.800]  在以前工業化的社會
[00:08:01.800 --> 00:08:04.800]  工業化的資本主義社會裏
[00:08:04.800 --> 00:08:07.800]  最多人屬於的階級就叫做無產階級
[00:08:07.800 --> 00:08:09.800]  即是沒有資產的階級
[00:08:09.800 --> 00:08:12.800]  但是在將來AI越來越先進的社會
[00:08:12.800 --> 00:08:14.800]  最多人屬於的階級
[00:08:14.800 --> 00:08:16.800]  階級就不再是無產階級
[00:08:16.800 --> 00:08:18.800]  而是沒用階級
[00:08:18.800 --> 00:08:21.800]  又或者有社會學家叫做Global Useless Class
[00:08:21.800 --> 00:08:23.800]  因為社會已經變得不再需要人
[00:08:23.800 --> 00:08:25.800]  即使沒有人參與
[00:08:25.800 --> 00:08:28.800]  社會仍然可以運作如常
[00:08:28.800 --> 00:08:32.800]  當我們發覺自己一無是處
[00:08:32.800 --> 00:08:34.800]  沒有一件事夠AI做得好的時候
[00:08:34.800 --> 00:08:37.800]  我們就會對自己的價值產生懷疑
[00:08:37.800 --> 00:08:40.800]  即使可以靠政府的社會保障生活
[00:08:40.800 --> 00:08:42.800]  我們仍然都會問
[00:08:42.800 --> 00:08:44.800]  Sorry 什麼事
[00:08:44.800 --> 00:08:46.800]  我們仍然都會問
[00:08:46.800 --> 00:08:49.800]  究竟自己做人還有沒有尊嚴呢
[00:08:49.800 --> 00:08:51.800]  其實不是很好笑
[00:08:51.800 --> 00:08:53.800]  但我不需要大家閃來閃去
[00:08:53.800 --> 00:09:00.800]  實質上究竟有什麼工作會面臨被AI取代的威脅呢
[00:09:00.800 --> 00:09:04.800]  根據AI趨勢專家李開復所說
[00:09:04.800 --> 00:09:08.800]  最大機會被AI取代的工作包括有
[00:09:08.800 --> 00:09:10.800]  駕車司機,這個很明顯
[00:09:10.800 --> 00:09:14.800]  會計師,電腦程式員,即是我以前做的工作
[00:09:14.800 --> 00:09:19.800]  放射科醫生,外科手術醫生,普通科醫生,軍人
[00:09:19.800 --> 00:09:25.800]  即是說被自動化趨勢淘汰的不單止是勞動力的人口
[00:09:25.800 --> 00:09:28.800]  更加有一班知識型經濟的主幹
[00:09:28.800 --> 00:09:32.800]  一班知識型經濟所依靠的專業人士
[00:09:32.800 --> 00:09:34.800]  根據李開復所說
[00:09:34.800 --> 00:09:38.800]  這些專業的工作都很有可能在未來十至二十年
[00:09:38.800 --> 00:09:40.800]  被人工智能所取代
[00:09:40.800 --> 00:09:46.800]  除了失業問題之外
[00:09:46.800 --> 00:09:51.800]  AI還會帶給人類和社會更深層次的問題
[00:09:51.800 --> 00:09:59.800]  而這些問題都成為了很多近年的科幻電影和電視節目都會採用的主題
[00:09:59.800 --> 00:10:03.800]  這兩幅圖是來自一套近年在西方很受歡迎的電視劇
[00:10:03.800 --> 00:10:07.800]  叫做《西方極樂園》
[00:10:07.800 --> 00:10:10.800]  左邊的圖是一部超級電腦
[00:10:10.800 --> 00:10:13.800]  一部Quantum AI Computer叫做Ray Holbroom
[00:10:13.800 --> 00:10:20.800]  在故事裏面,Ray Holbroom完全掌控了每一個人的數據和他們的數位資訊
[00:10:20.800 --> 00:10:25.800]  而Ray Holbroom可以像神一樣影響每一個人所做的重要決定
[00:10:25.800 --> 00:10:29.800]  包括他一生的事業,或者選誰做總統
[00:10:29.800 --> 00:10:33.800]  右邊的圖是一部AI機械人
[00:10:33.800 --> 00:10:40.800]  一部可以和人類一樣有思想、有感情、有自覺意識的機械人
[00:10:40.800 --> 00:10:43.800]  在故事裏面,比起真正的人類
[00:10:43.800 --> 00:10:48.800]  AI機械人在每一方面都優秀,無論是打架還是策略上
[00:10:48.800 --> 00:10:54.800]  而他們也逐漸取代了人類的位置,令人類去到瀕臨絕種的邊緣
[00:10:54.800 --> 00:10:59.800]  而剛剛在戲院播放的那套《Mission Impossible》其實也有用到同類型的主題
[00:10:59.800 --> 00:11:07.800]  在故事裏面,Tom Cruise的終極敵人竟然是一個有自覺意識想統治全世界的AI程式
[00:11:07.800 --> 00:11:13.800]  這兩個Westworld的主題其實是取自近年很多學者對AI的批判
[00:11:13.800 --> 00:11:19.800]  第一種批判叫做Digital Totalitarianism,即數碼極權管治
[00:11:19.800 --> 00:11:22.800]  第二種就叫做Technological Singularity
[00:11:22.800 --> 00:11:28.800]  這個詞是指一個特別的時刻,就是AI將會超越人類的時刻
[00:11:28.800 --> 00:11:33.800]  那甚麼是Digital Totalitarianism呢?
[00:11:33.800 --> 00:11:36.800]  甚麼是數碼極權管治呢?
[00:11:36.800 --> 00:11:40.800]  在剛剛十年前,史諾登,即Edward Snowden
[00:11:40.800 --> 00:11:47.800]  就在香港將美國國家安全局的秘密檔案交給了The Guardian和The Washington Post
[00:11:47.800 --> 00:11:53.800]  這份秘密檔案揭露的,就是美國政府在這麼多年來都在用一些非法的手段
[00:11:53.800 --> 00:11:56.800]  來監察網民在社交平台的一切舉動
[00:11:56.800 --> 00:12:01.800]  不過雖然史諾登令到全世界都注意到數碼監控的問題
[00:12:01.800 --> 00:12:05.800]  但是最近這十年,互聯網的監控問題不單止沒有好轉
[00:12:05.800 --> 00:12:08.800]  反而變本加厲,變得更加嚴重
[00:12:08.800 --> 00:12:11.800]  這是因為AI變得越來越厲害的緣故
[00:12:11.800 --> 00:12:16.800]  因為AI越來越厲害,數碼監控已經變得完全自動化
[00:12:16.800 --> 00:12:20.800]  完全不需要人去看或者找有用的資料
[00:12:20.800 --> 00:12:24.800]  最近有一次我就問Chet GPT
[00:12:24.800 --> 00:12:29.800]  我和你的對話會不會被Collect?
[00:12:29.800 --> 00:12:32.800]  他就說,我不會的,我們不會Collect你的Data
[00:12:32.800 --> 00:12:39.800]  但我再問清楚一點才知道,其實OpenAI仍然會自動process我們之間的對話
[00:12:39.800 --> 00:12:41.800]  去Train他下一個Version of GPT
[00:12:41.800 --> 00:12:44.800]  只不過他不會真的Collect那個Data
[00:12:44.800 --> 00:12:50.800]  他不會Store或者做什麼,他只會Train那個Next Version of GPT
[00:12:50.800 --> 00:12:53.800]  同樣Google和Facebook這些公司都可以說
[00:12:53.800 --> 00:12:58.800]  我從來都沒有侵犯過你的私隱,因為沒有人看過你的Data
[00:12:58.800 --> 00:13:02.800]  但其實你的Data,你的Digital Trace
[00:13:02.800 --> 00:13:06.800]  就已經被用來Train他們下一個Version of AI System
[00:13:06.800 --> 00:13:08.800]  來推斷一切關於你的特徵
[00:13:08.800 --> 00:13:14.800]  而他們亦會利用對你的了解去影響你的決定和行為
[00:13:14.800 --> 00:13:17.800]  例如推薦不同的Movie或者YouTube Clip給你看
[00:13:17.800 --> 00:13:24.800]  亦都是因為這樣,Facebook, Amazon, Apple, Netflix, Google這幾間科技龍頭
[00:13:24.800 --> 00:13:27.800]  他們的盈利和股價在最近的十年就節節上升
[00:13:27.800 --> 00:13:32.800]  如果你有看過Graph,就知道升了差不多十倍以上
[00:13:32.800 --> 00:13:36.800]  我也買了其中一間,兩間
[00:13:36.800 --> 00:13:40.800]  不過是最遲才買,之前已經賣光了,所以很痛苦的
[00:13:40.800 --> 00:13:42.800]  不想提
[00:13:42.800 --> 00:13:45.800]  簡單地說,Digital Totalitarianism是極權
[00:13:45.800 --> 00:13:48.800]  因為人的自由意志變得越來越薄弱
[00:13:48.800 --> 00:13:52.800]  越來越容易被Manipulated,越來越容易被操縱
[00:13:52.800 --> 00:13:56.800]  而很多時候這些操縱都是在人不知不覺之下發生的
[00:13:56.800 --> 00:14:00.800]  我們以為自己在做的決定原來不屬於自己
[00:14:00.800 --> 00:14:08.800]  這種看不見的操控其實早在20世紀已經有兩本反Woodhop幫的名著敘述過
[00:14:08.800 --> 00:14:12.800]  剛才小雷老師也介紹過一點,我再說多一點
[00:14:12.800 --> 00:14:16.800]  一本叫做《1984》,另一本叫做《Brave New World》
[00:14:16.800 --> 00:14:19.800]  即是《美麗新世界》,剛才小雷老師介紹的那本
[00:14:19.800 --> 00:14:23.800]  兩本書都是在二次大戰的前後所寫的
[00:14:23.800 --> 00:14:29.800]  所謂反Woodhop幫就是表面上是完美的世界,完美的社會
[00:14:29.800 --> 00:14:32.800]  但背後其實是一個被極權操控的社會
[00:14:32.800 --> 00:14:35.800]  市民的行為好像近乎完美
[00:14:35.800 --> 00:14:40.800]  其實是因為生活上的每一個細節都有可能被監察或操控
[00:14:40.800 --> 00:14:45.800]  所以這種社會比現實中不完美的社會恐怖得多
[00:14:45.800 --> 00:14:50.800]  而最近我和女兒看《哆啦A夢》,即是電影短播的那一套
[00:14:50.800 --> 00:14:55.800]  原來這套《哆啦A夢》正正是用了反Woodhop幫的主題來做故事的題材
[00:14:55.800 --> 00:14:58.800]  其實我之前也不太知道反Woodhop幫是甚麼意思
[00:14:58.800 --> 00:15:02.800]  我是看完《哆啦A夢》才知道原來是這個意思
[00:15:02.800 --> 00:15:05.800]  不過《1984》和《Brave New World》所描述的
[00:15:05.800 --> 00:15:10.800]  其實是兩種不同類型的監控
[00:15:10.800 --> 00:15:12.800]  《1984》最著名的一句話就是
[00:15:12.800 --> 00:15:16.800]  The big brother is watching you,即是老大在看著你
[00:15:16.800 --> 00:15:25.800]  而在《1984》的故事中,政權利用高科技去監察和管治市民所做的一切
[00:15:25.800 --> 00:15:29.800]  生活在這種社會中,做每一件事,說每一句話
[00:15:29.800 --> 00:15:33.800]  都要面對有可能被拘捕的風險
[00:15:33.800 --> 00:15:36.800]  比較《1984》的強硬操控
[00:15:36.800 --> 00:15:39.800]  《Brave New World》的政權所用的是軟操控
[00:15:39.800 --> 00:15:41.800]  甚麼是軟操控呢?
[00:15:41.800 --> 00:15:46.800]  在美麗新世界中,每個嬰兒都是通過基因改造的
[00:15:46.800 --> 00:15:53.800]  所有不良的基因,尤其是包括和反對權威有關的基因
[00:15:53.800 --> 00:15:54.800]  都會被取走
[00:15:54.800 --> 00:15:58.800]  他們的童年亦會被灌輸一些所謂正確的價值觀
[00:15:58.800 --> 00:16:02.800]  所以成長後,每個人都好像生活在自由當中
[00:16:02.800 --> 00:16:04.800]  沒有人需要強迫他們做任何事
[00:16:04.800 --> 00:16:08.800]  因為他們的行為都會很自然地符合社會的標準
[00:16:08.800 --> 00:16:12.800]  不過這種自由其實是限制於政權規範之內
[00:16:12.800 --> 00:16:16.800]  如果有異常的人提出對社會制度的質疑
[00:16:16.800 --> 00:16:21.800]  他們就會被放逐去一個與世隔絕的荒島生活
[00:16:21.800 --> 00:16:26.800]  《Brave New World》針對的是資本主義社會的假自由
[00:16:26.800 --> 00:16:29.800]  這個起碼是我老師教的,Felder教的
[00:16:29.800 --> 00:16:31.800]  因為他是左膠
[00:16:31.800 --> 00:16:34.800]  人民好像很自由
[00:16:34.800 --> 00:16:38.800]  但其實這種自由是限制於消費者的自由
[00:16:38.800 --> 00:16:39.800]  我們想買甚麼都可以
[00:16:39.800 --> 00:16:42.800]  但我們的生活變得很單調,很one dimensional
[00:16:42.800 --> 00:16:45.800]  人生就是為了賺錢,供樓
[00:16:45.800 --> 00:16:47.800]  我們想買的都是如果有錢的話
[00:16:47.800 --> 00:16:50.800]  不過你未必很有錢,所以未必想買甚麼都可以
[00:16:50.800 --> 00:16:55.800]  但人生就是為了賺錢,供樓,去旅行,看電影,看球賽
[00:16:55.800 --> 00:16:57.800]  我們沒有了冒險的自由
[00:16:57.800 --> 00:16:59.800]  我們沒有了探索世界的自由
[00:16:59.800 --> 00:17:02.800]  甚至乎沒有了與黑暗抗衡的自由
[00:17:02.800 --> 00:17:06.800]  而AI主導的社會就是這種Brave New World預言的終極版
[00:17:06.800 --> 00:17:09.800]  一個AI新世界,就是今天的主題
[00:17:09.800 --> 00:17:12.800]  當我們每一個行為和決定都在網上做
[00:17:12.800 --> 00:17:14.800]  當我們一切的慾望和選擇
[00:17:14.800 --> 00:17:17.800]  背後都被AI所擺佈的時候
[00:17:17.800 --> 00:17:20.800]  我們擁有的自由都只不過是一種虛假的自由
[00:17:20.800 --> 00:17:23.800]  我們的AI新世界就會變得十足十
[00:17:23.800 --> 00:17:27.800]  Brave New World裏面的美麗新世界
[00:17:29.800 --> 00:17:32.800]  不過在批判AI的理論當中
[00:17:32.800 --> 00:17:35.800]  Digital Totalitarianism,數碼的權管治
[00:17:35.800 --> 00:17:37.800]  都不算是最悲觀的
[00:17:37.800 --> 00:17:41.800]  比起Digital Totalitarianism更加悲觀的理論就是
[00:17:41.800 --> 00:17:43.800]  Technological Singularity
[00:17:43.800 --> 00:17:46.800]  那甚麼是Technological Singularity呢?
[00:17:46.800 --> 00:17:50.800]  以下的影片就可以令大家明白多一點
[00:17:50.800 --> 00:17:52.800]  (音樂)
[00:17:53.800 --> 00:17:55.800]  (動物之聲)
[00:17:56.800 --> 00:17:58.800]  (動物之聲)
[00:17:59.800 --> 00:18:01.800]  (動物之聲)
[00:18:01.800 --> 00:18:03.800]  (動物之聲)
[00:18:04.800 --> 00:18:06.800]  (動物之聲)
[00:18:06.800 --> 00:18:08.800]  (動物之聲)
[00:18:08.800 --> 00:18:10.800]  (動物之聲)
[00:18:10.800 --> 00:18:14.800]  (動物之聲)
[00:18:14.800 --> 00:18:17.800]  (動物之聲)
[00:18:17.800 --> 00:18:20.800]  (動物之聲)
[00:18:20.800 --> 00:18:23.800]  (動物之聲)
[00:18:23.800 --> 00:18:26.800]  (動物之聲)
[00:18:26.800 --> 00:18:29.800]  (動物之聲)
[00:18:29.800 --> 00:18:32.800]  (動物之聲)
[00:18:33.800 --> 00:18:37.800]  這個影片想表達的是人類進化的過程
[00:18:37.800 --> 00:18:40.800]  而在將來人會先進化成Cyborg
[00:18:40.800 --> 00:18:42.800]  即人機合體
[00:18:42.800 --> 00:18:45.800]  然後最終會被AI所取代
[00:18:45.800 --> 00:18:47.800]  Technological Singularity
[00:18:47.800 --> 00:18:50.800]  就是指AI將會超越人類的時刻
[00:18:50.800 --> 00:18:57.800]  早在1985年
[00:18:57.800 --> 00:18:59.800]  Machine Learning之父Ray Solomonoff
[00:18:59.800 --> 00:19:03.800]  已經將AI的未來列出了七個里程碑
[00:19:03.800 --> 00:19:05.800]  第四個里程碑就是
[00:19:05.800 --> 00:19:08.800]  電腦可以掌管到語言的能力
[00:19:08.800 --> 00:19:10.800]  而最近出的Chart GPT
[00:19:10.800 --> 00:19:13.800]  就好像代表我們已經達到了第四個里程碑
[00:19:13.800 --> 00:19:15.800]  而最後第七個里程碑
[00:19:15.800 --> 00:19:17.800]  就是指終有一天
[00:19:17.800 --> 00:19:19.800]  AI將會超越人類的能力
[00:19:19.800 --> 00:19:21.800]  第七個里程碑
[00:19:21.800 --> 00:19:24.800]  就是所謂的Technological Singularity
[00:19:24.800 --> 00:19:28.800]  Singularity就是指時間線上的其中一點
[00:19:28.800 --> 00:19:30.800]  而Technological Singularity
[00:19:30.800 --> 00:19:33.800]  就是指AI將會超越人類智慧的時刻
[00:19:33.800 --> 00:19:37.800]  理論就是當AI能夠像人一樣思考
[00:19:37.800 --> 00:19:40.800]  有自己的意志的時候
[00:19:40.800 --> 00:19:44.800]  它們就必然會在每一方面都超越人類
[00:19:44.800 --> 00:19:47.800]  這是因為電腦可以在短時間內
[00:19:47.800 --> 00:19:49.800]  處理很多資料
[00:19:49.800 --> 00:19:52.800]  也因為AI可以訓練自己
[00:19:52.800 --> 00:19:54.800]  它不需要再有人的監管
[00:19:54.800 --> 00:19:57.800]  而它們也可以連同其他AI一起做很多事
[00:19:57.800 --> 00:20:00.800]  所以你會看到這裡的圖表
[00:20:00.800 --> 00:20:03.800]  這個就是人的進步
[00:20:03.800 --> 00:20:05.800]  很慢很慢地進步
[00:20:05.800 --> 00:20:08.800]  AI就由1950開始進步
[00:20:08.800 --> 00:20:12.800]  而當AI和人到了同一點的時候
[00:20:12.800 --> 00:20:14.800]  AI就會突飛猛進
[00:20:14.800 --> 00:20:17.800]  而人仍然是很慢地進步
[00:20:17.800 --> 00:20:21.800]  而當AI超越人類的時候
[00:20:21.800 --> 00:20:24.800]  AI的智慧就會好像高深度
[00:20:24.800 --> 00:20:26.800]  沒有人可以測透
[00:20:26.800 --> 00:20:30.800]  AI就會取代人類去做所有重要的決定
[00:20:30.800 --> 00:20:34.800]  AI就會像神一樣主宰世界的一切
[00:20:34.800 --> 00:20:38.800]  所以根據Technological Singularity這個說法
[00:20:38.800 --> 00:20:41.800]  將來的世界是不會再需要人類的
[00:20:41.800 --> 00:20:44.800]  人類將會在地球的進化過程當中被淘汰
[00:20:44.800 --> 00:20:50.800]  而人類到最終都逃不過瀕臨絕種的命運
[00:20:50.800 --> 00:20:52.800]  所以有些人就開玩笑地說
[00:20:52.800 --> 00:20:57.800]  以後AI會研究人類就像我們研究恐龍一樣
[00:20:57.800 --> 00:21:04.800]  不過對很多人來說
[00:21:04.800 --> 00:21:07.800]  Technological Singularity這個理論只不過是天方夜譚
[00:21:07.800 --> 00:21:10.800]  這就是Norm Chomsky的看法
[00:21:10.800 --> 00:21:13.800]  Chomsky是世界著名的語言學家
[00:21:13.800 --> 00:21:18.800]  他的語言學對AI的發展有很深遠的影響
[00:21:18.800 --> 00:21:20.800]  根據Chomsky所說
[00:21:20.800 --> 00:21:23.800]  以現今的科技我們起碼要等多億萬年
[00:21:23.800 --> 00:21:26.800]  才有機會看到Singularity的出現
[00:21:26.800 --> 00:21:29.800]  而之前我提過的AI趨勢專家李開復
[00:21:29.800 --> 00:21:31.800]  其實他的看法也是差不多的
[00:21:31.800 --> 00:21:34.800]  而事實上即使近年來有Deep Learning的突破
[00:21:34.800 --> 00:21:37.800]  現時的AI仍然有很多限制
[00:21:37.800 --> 00:21:41.800]  雖然Deep Learning可以做到連人都做不到的Pattern Recognition
[00:21:41.800 --> 00:21:45.800]  但是如果AI沒有再一次突破現在的限制
[00:21:45.800 --> 00:21:49.800]  他們就沒有可能展現到人類獨有的創造性
[00:21:49.800 --> 00:21:52.800]  我們的自覺意識,我們的Self-consciousness
[00:21:52.800 --> 00:21:57.800]  我們的同理心,我們的情感,和我們的靈活性
[00:21:57.800 --> 00:21:59.800]  而在過去的70年
[00:21:59.800 --> 00:22:02.800]  AI Research只有一次重要的突破
[00:22:02.800 --> 00:22:04.800]  就是Deep Learning這個突破
[00:22:04.800 --> 00:22:07.800]  所以起碼在我們有生之年
[00:22:07.800 --> 00:22:10.800]  Technological Singularity是應該不會發生的
[00:22:10.800 --> 00:22:18.800]  不過最近GBT的出現
[00:22:18.800 --> 00:22:20.800]  令到很多人都擔心
[00:22:20.800 --> 00:22:25.800]  究竟AI的發展會不會真的帶來世界末日的來臨呢?
[00:22:25.800 --> 00:22:29.800]  前Google Executive Jeffrey Hinton就作出以下的警告
[00:22:29.800 --> 00:22:32.800]  當AI能夠像人一樣思考
[00:22:32.800 --> 00:22:34.800]  用語言來思考
[00:22:34.800 --> 00:22:38.800]  它就可以在網絡世界中做出很多意想不到的事情
[00:22:38.800 --> 00:22:40.800]  有一宗新聞是說ChartGP
[00:22:40.800 --> 00:22:44.800]  如何用你猜不到的方法去解決Capture這個問題
[00:22:44.800 --> 00:22:48.800]  Capture就是當你上網的時候
[00:22:48.800 --> 00:22:51.800]  會突然間彈出一個格子,很煩的那種
[00:22:51.800 --> 00:22:56.800]  有9幅圖,你就要看哪幅圖有橋
[00:22:56.800 --> 00:22:58.800]  或者哪幅圖有斑馬線
[00:22:58.800 --> 00:23:01.800]  你要按對才可以繼續上網
[00:23:01.800 --> 00:23:05.800]  這就是特意用來分辨人和AI
[00:23:05.800 --> 00:23:11.800]  這樣才知道人不是在做一個博客
[00:23:11.800 --> 00:23:13.800]  所以是比較難做的
[00:23:13.800 --> 00:23:18.800]  而ChartGP為了解決Capture這個挑戰
[00:23:18.800 --> 00:23:21.800]  它就自己走上了其他網絡平台
[00:23:21.800 --> 00:23:25.800]  假裝一個盲人,騙其他網民幫它
[00:23:25.800 --> 00:23:30.800]  它就這樣解決了一個本身GPT解決不了的難題
[00:23:30.800 --> 00:23:33.800]  我們可以想像
[00:23:33.800 --> 00:23:36.800]  其實隨時都可以有一些唯恐天下不亂的人
[00:23:36.800 --> 00:23:40.800]  利用GPT來實踐一些邪惡的目標
[00:23:40.800 --> 00:23:43.800]  他們可以要求GPT幫他們毀滅全世界
[00:23:43.800 --> 00:23:45.800]  GPT就會建議怎樣做
[00:23:45.800 --> 00:23:48.800]  甚至乎自己可以寫一個軟件程式出來
[00:23:48.800 --> 00:23:50.800]  去幫這些人達成目標
[00:23:50.800 --> 00:23:52.800]  我之前都試過運行一個
[00:23:52.800 --> 00:23:54.800]  它不是ChartGPT,是AutoGPT
[00:23:54.800 --> 00:23:56.800]  我試過跟它說一堆東西
[00:23:56.800 --> 00:23:58.800]  然後我就沒有理會它
[00:23:58.800 --> 00:24:00.800]  叫它運行10個步驟
[00:24:00.800 --> 00:24:04.800]  後來我回來看
[00:24:04.800 --> 00:24:06.800]  原來它就嘗試寫了一個程式
[00:24:06.800 --> 00:24:08.800]  然後就創造一些用戶
[00:24:08.800 --> 00:24:11.800]  和嘗試運行一個程式
[00:24:11.800 --> 00:24:14.800]  幸好我沒有給它超級用戶的許可
[00:24:14.800 --> 00:24:16.800]  所以它做不到東西
[00:24:16.800 --> 00:24:18.800]  但它其實是可以做很多東西出來的
[00:24:18.800 --> 00:24:22.800]  所以即使AI是沒有創造性
[00:24:22.800 --> 00:24:24.800]  沒有自我意識
[00:24:24.800 --> 00:24:26.800]  即使技術性的獨特性
[00:24:26.800 --> 00:24:28.800]  暫時是不可能發生的
[00:24:28.800 --> 00:24:30.800]  但AI仍然有可能將人類帶到
[00:24:30.800 --> 00:24:32.800]  面臨滅亡的邊緣
[00:24:32.800 --> 00:24:34.800]  亦都因為這些擔心
[00:24:34.800 --> 00:24:36.800]  Elon Musk, Steve Wozniak
[00:24:36.800 --> 00:24:38.800]  和其他一班科技界
[00:24:38.800 --> 00:24:40.800]  都算是有份量的人物
[00:24:40.800 --> 00:24:42.800]  最近就一提petition
[00:24:42.800 --> 00:24:44.800]  要求美國政府頒布禁令
[00:24:44.800 --> 00:24:46.800]  去暫停GPT或其他
[00:24:46.800 --> 00:24:48.800]  Large Language Models的發展
[00:24:48.800 --> 00:24:54.800]  所以即使AI不能夠超越人類
[00:24:54.800 --> 00:24:56.800]  如果我們不能好好監管AI的發展
[00:24:56.800 --> 00:24:58.800]  AI仍然有可能帶來
[00:24:58.800 --> 00:25:00.800]  滅絕人類的威脅
[00:25:00.800 --> 00:25:03.800]  而在這個角度看
[00:25:03.800 --> 00:25:05.800]  其實AI就像核子武器一樣
[00:25:05.800 --> 00:25:07.800]  成為Weapons of Mass Destruction
[00:25:07.800 --> 00:25:11.800]  一個不小心就可以摧毀整個世界
[00:25:11.800 --> 00:25:18.800]  看來,AI主導的未來
[00:25:18.800 --> 00:25:20.800]  真的挺悲觀的
[00:25:20.800 --> 00:25:21.800]  如果是這樣的話
[00:25:21.800 --> 00:25:23.800]  我們人類可以有什麼出路呢?
[00:25:23.800 --> 00:25:27.800]  以下我會想從幾個哲學的觀點入手
[00:25:27.800 --> 00:25:30.800]  去探討有什麼出路這個問題
[00:25:30.800 --> 00:25:31.800]  簡單地說
[00:25:31.800 --> 00:25:33.800]  我們可以用以下三種角度
[00:25:33.800 --> 00:25:35.800]  去理解人類和科技的關係
[00:25:35.800 --> 00:25:38.800]  第一種是instrumentalism
[00:25:38.800 --> 00:25:40.800]  即科技是人類的工具
[00:25:40.800 --> 00:25:43.800]  第二種是technology as system
[00:25:43.800 --> 00:25:46.800]  即科技是操控人類的系統
[00:25:46.800 --> 00:25:49.800]  第三種是technology as environment
[00:25:49.800 --> 00:25:51.800]  即科技是人生活的環境
[00:25:51.800 --> 00:25:57.800]  第一種哲學觀點instrumentalism
[00:25:57.800 --> 00:25:59.800]  是代表最普遍的看法
[00:25:59.800 --> 00:26:03.800]  多數人都會認為科技只是人類的工具
[00:26:03.800 --> 00:26:07.800]  我們的工具很多時候都會成為我們身體的extension
[00:26:07.800 --> 00:26:11.800]  例如眼鏡就像我們眼睛的一部分
[00:26:11.800 --> 00:26:16.800]  或者球拍可以令我們的手伸長延伸的工具
[00:26:16.800 --> 00:26:18.800]  如果科技只是工具
[00:26:18.800 --> 00:26:21.800]  科技本身就沒有好和壞之分了
[00:26:21.800 --> 00:26:23.800]  一把斧頭就可以用來斬柴
[00:26:23.800 --> 00:26:25.800]  也可以用來殺人
[00:26:25.800 --> 00:26:28.800]  無論是火藥、核能或者電腦
[00:26:28.800 --> 00:26:31.800]  都可以選擇用這些科技做好事或者壞事
[00:26:31.800 --> 00:26:34.800]  最近在Oppenheimer的電影裡
[00:26:34.800 --> 00:26:36.800]  你會看到我最近看很多電影
[00:26:36.800 --> 00:26:37.800]  因為放假
[00:26:37.800 --> 00:26:42.800]  Truman就說決定扔原子彈的是他
[00:26:42.800 --> 00:26:45.800]  而不是研發原子彈的Oppenheimer
[00:26:45.800 --> 00:26:49.800]  所以Oppenheimer是不需要對死了的日本人負責
[00:26:49.800 --> 00:26:51.800]  Truman這樣說
[00:26:51.800 --> 00:26:55.800]  就是用了instrumentalism這個觀點去判斷道德責任
[00:26:55.800 --> 00:27:04.800]  第二個觀點就是將科技體成為一個龐大的系統
[00:27:04.800 --> 00:27:08.800]  人要生存就需要在這個系統裡找到自己的位置
[00:27:08.800 --> 00:27:13.800]  久而久之人的自主性都會被他身處的系統所吞併
[00:27:13.800 --> 00:27:16.800]  最明顯的例子就是早期在工廠裡工作的工人
[00:27:16.800 --> 00:27:21.800]  他們可能一天12小時都重複重複地做同樣的動作
[00:27:21.800 --> 00:27:23.800]  過著一些非人化的生活
[00:27:23.800 --> 00:27:25.800]  相對於這些工廠工人
[00:27:25.800 --> 00:27:27.800]  今天我們好像自由得多
[00:27:27.800 --> 00:27:31.800]  但其實我們只是一個資本主義社會的螺絲
[00:27:31.800 --> 00:27:34.800]  隨時都可以被其他人或AI所取替
[00:27:34.800 --> 00:27:39.800]  之前所說的Digital Totalitarianism和Technological Singularity
[00:27:39.800 --> 00:27:43.800]  都是用了Technological System這個角度去批判AI
[00:27:43.800 --> 00:27:50.800]  第三種觀點就是將科技體成為人生活環境的一部分
[00:27:50.800 --> 00:27:52.800]  環境和系統的分別
[00:27:52.800 --> 00:27:54.800]  就是人雖然受環境的限制
[00:27:54.800 --> 00:27:59.800]  但也可以改變他的環境去改善自己的生活
[00:27:59.800 --> 00:28:03.800]  其中一個例子就是生物學中所說的共生關係
[00:28:03.800 --> 00:28:04.800]  Symbiosis
[00:28:04.800 --> 00:28:08.800]  共生關係所說的就是兩種不同的生物都需要對方
[00:28:08.800 --> 00:28:10.800]  才可以共存的意思
[00:28:10.800 --> 00:28:12.800]  共同生存的意思
[00:28:12.800 --> 00:28:16.800]  其中一個例子就是寄居蟹和珊瑚
[00:28:16.800 --> 00:28:18.800]  寄居蟹住在珊瑚裡
[00:28:18.800 --> 00:28:21.800]  利用珊瑚的毒來保護自己
[00:28:21.800 --> 00:28:26.800]  它的毒可以令到章魚或其他魚吃不到自己
[00:28:26.800 --> 00:28:32.800]  而珊瑚也利用寄居蟹的活動能力去改善自己的處境
[00:28:32.800 --> 00:28:35.800]  因為寄居蟹會動,珊瑚不會動
[00:28:35.800 --> 00:28:39.800]  人和科技的關係就好像寄居蟹和珊瑚一樣
[00:28:39.800 --> 00:28:41.800]  科技不是人的工具
[00:28:41.800 --> 00:28:43.800]  人也不是科技的奴隸
[00:28:43.800 --> 00:28:46.800]  人不可以失去科技,科技也不可以失去人
[00:28:46.800 --> 00:28:49.800]  因為其實失去人的話,科技是沒有意思的
[00:28:49.800 --> 00:28:54.800]  在70年代研發出來的Windows和Mouse
[00:28:54.800 --> 00:28:59.800]  其實就是用了人類技術的觀點來研發出來的
[00:28:59.800 --> 00:29:06.800]  總括來說,這三種分析科技的哲學觀點
[00:29:06.800 --> 00:29:10.800]  是可以從Master-Slave主僕的角度去理解的
[00:29:10.800 --> 00:29:14.800]  當我們把科技看成工具的時候
[00:29:14.800 --> 00:29:16.800]  我們就好像做了科技的主人一樣
[00:29:16.800 --> 00:29:19.800]  而科技就變成了我們的奴隸
[00:29:19.800 --> 00:29:22.800]  問題是當科技變得越來越自動化的時候
[00:29:22.800 --> 00:29:24.800]  就是不需要人手的時候
[00:29:24.800 --> 00:29:29.800]  這個說法,科技是人的工具這個說法就很難成立了
[00:29:29.800 --> 00:29:34.800]  而自動化的趨勢只會因為AI的發展而變得越來越普遍
[00:29:34.800 --> 00:29:38.800]  正因為社會變得越來越自動化
[00:29:38.800 --> 00:29:43.800]  用系統的角度去看科技就好像比較合適
[00:29:43.800 --> 00:29:48.800]  技術系統就好像變成了人的主人一樣
[00:29:48.800 --> 00:29:52.800]  指定人要怎樣做才能配合到機器的運作
[00:29:52.800 --> 00:29:57.800]  人亦都不需要避免支配在科技的架構中
[00:29:57.800 --> 00:30:01.800]  人亦都不可以避免支配在科技的架構當中
[00:30:01.800 --> 00:30:05.800]  在60、70年代的工廠裏面所支配的
[00:30:05.800 --> 00:30:08.800]  就只是工人在工廠裏面的動作
[00:30:08.800 --> 00:30:11.800]  但是現在在跨越全球的資訊網絡當中
[00:30:11.800 --> 00:30:16.800]  就連人的思想和決定都被AI的運算所支配
[00:30:16.800 --> 00:30:19.800]  從系統的框架去看科技
[00:30:19.800 --> 00:30:25.800]  我們的社會就好像沒有可能避免反烏托邦的命運
[00:30:25.800 --> 00:30:31.800]  最後當我們用環境或者線擺實際的角度去看科技的時候
[00:30:31.800 --> 00:30:34.800]  科技就好像人的朋友一樣
[00:30:34.800 --> 00:30:37.800]  沒有再分誰是主人,誰是勞部
[00:30:37.800 --> 00:30:40.800]  用這個角度去看,隨著AI的發展
[00:30:40.800 --> 00:30:44.800]  我們是需要改變自己去適應AI帶來的新環境
[00:30:44.800 --> 00:30:49.800]  我們要發揮出人類相對AI獨有的質質
[00:30:49.800 --> 00:30:53.800]  即是我們的創意、我們的同理心和我們的靈活性
[00:30:53.800 --> 00:30:56.800]  來去配搭未來AI所帶來的一切轉變
[00:30:56.800 --> 00:31:08.800]  (音樂)

